{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/envs/deep-learning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '\\t'\n",
    "end_token = '\\n'\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = []\n",
    "target_seqs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines)-1)]:\n",
    "    input_seq, target_seq = line.split('\\t')\n",
    "    \n",
    "    target_seq = start_token + target_seq + end_token\n",
    "    \n",
    "    input_seqs.append(input_seq)\n",
    "    target_seqs.append(target_seq)\n",
    "    \n",
    "    for token in input_seq:\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "            \n",
    "    for token in target_seq:\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "            \n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "max_encoder_seq_length = max([len(seq) for seq in input_seqs])\n",
    "max_decoder_seq_length = max([len(seq) for seq in target_seqs])\n",
    "\n",
    "input_token_index = dict([(token, index) for index, token in enumerate(input_tokens)])\n",
    "target_token_index = dict([(token, index) for index, token in enumerate(target_tokens)])\n",
    "\n",
    "rev_input_token_index = dict([(index, token) for index, token in enumerate(input_tokens)])\n",
    "rev_target_token_index = dict([(index, token) for index, token in enumerate(target_tokens)])\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_seqs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_seqs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_seqs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_seq, target_seq) in enumerate(zip(input_seqs, target_seqs)):\n",
    "    for j, token in enumerate(input_seq):\n",
    "        encoder_input_data[i, j, input_token_index[token]] = 1.\n",
    "    for j, token in enumerate(target_seq):\n",
    "        decoder_input_data[i, j, target_token_index[token]] = 1.\n",
    "        if j > 0:\n",
    "            decoder_target_data[i, j-1, target_token_index[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None,None,num_encoder_tokens), dtype=tf.float32, name='encoder_inputs')\n",
    "decoder_inputs = tf.placeholder(shape=(None,None,num_decoder_tokens), dtype=tf.float32, name='decoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None,None,num_decoder_tokens), dtype=tf.float32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(latent_dim)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs,\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(latent_dim)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs,\n",
    "    dtype=tf.float32,\n",
    "    initial_state=encoder_final_state,\n",
    "    scope='plain_decoder'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, num_decoder_tokens)\n",
    "decoder_predicition = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=decoder_targets,\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_targets:0' shape=(?, ?, 94) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 94) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(input_data, batch_size=100):\n",
    "    num_batches = int(np.ceil(input_data.shape[0] / batch_size))\n",
    "    batches = []\n",
    "    for batch in np.arange(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = (batch+1) * batch_size\n",
    "        batches.append(input_data[start:end,:,:])\n",
    "        \n",
    "    return batches, num_batches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_batches, _ = create_batches(encoder_input_data, batch_size)\n",
    "decoder_input_batches, _ = create_batches(decoder_input_data, batch_size)\n",
    "decoder_target_batches, num_batches = create_batches(decoder_target_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_feed(batch_index):\n",
    "    return {\n",
    "        encoder_inputs: encoder_input_batches[batch_index],\n",
    "        decoder_inputs: decoder_input_batches[batch_index],\n",
    "        decoder_targets: decoder_target_batches[batch_index]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "\t minibatch loss: 1.491408224105835\n",
      "epoch 2\n",
      "\t minibatch loss: 1.4785189986228944\n",
      "epoch 3\n",
      "\t minibatch loss: 1.4645978176593781\n",
      "epoch 4\n",
      "\t minibatch loss: 1.4475791996717453\n",
      "epoch 5\n",
      "\t minibatch loss: 1.422972947359085\n",
      "epoch 6\n",
      "\t minibatch loss: 1.3895596253871918\n",
      "epoch 7\n",
      "\t minibatch loss: 1.356590126156807\n",
      "epoch 8\n",
      "\t minibatch loss: 1.3295823299884797\n",
      "epoch 9\n",
      "\t minibatch loss: 1.309317536354065\n",
      "epoch 10\n",
      "\t minibatch loss: 1.2950420951843262\n",
      "epoch 11\n",
      "\t minibatch loss: 1.2840724736452103\n",
      "epoch 12\n",
      "\t minibatch loss: 1.2710555845499039\n",
      "epoch 13\n",
      "\t minibatch loss: 1.2518272715806962\n",
      "epoch 14\n",
      "\t minibatch loss: 1.2267791444063187\n",
      "epoch 15\n",
      "\t minibatch loss: 1.2062312895059586\n",
      "epoch 16\n",
      "\t minibatch loss: 1.1920768052339554\n",
      "epoch 17\n",
      "\t minibatch loss: 1.1806173831224442\n",
      "epoch 18\n",
      "\t minibatch loss: 1.170484355688095\n",
      "epoch 19\n",
      "\t minibatch loss: 1.1617117249965667\n",
      "epoch 20\n",
      "\t minibatch loss: 1.15437109708786\n",
      "epoch 21\n",
      "\t minibatch loss: 1.1482348477840423\n",
      "epoch 22\n",
      "\t minibatch loss: 1.14305905520916\n",
      "epoch 23\n",
      "\t minibatch loss: 1.138650695681572\n",
      "epoch 24\n",
      "\t minibatch loss: 1.1348644256591798\n",
      "epoch 25\n",
      "\t minibatch loss: 1.131583205461502\n",
      "epoch 26\n",
      "\t minibatch loss: 1.1287061601877213\n",
      "epoch 27\n",
      "\t minibatch loss: 1.1261515283584596\n",
      "epoch 28\n",
      "\t minibatch loss: 1.123856914639473\n",
      "epoch 29\n",
      "\t minibatch loss: 1.1217754423618316\n",
      "epoch 30\n",
      "\t minibatch loss: 1.119871097803116\n",
      "epoch 31\n",
      "\t minibatch loss: 1.1181149703264237\n",
      "epoch 32\n",
      "\t minibatch loss: 1.1164831668138504\n",
      "epoch 33\n",
      "\t minibatch loss: 1.1149558925628662\n",
      "epoch 34\n",
      "\t minibatch loss: 1.1135187536478042\n",
      "epoch 35\n",
      "\t minibatch loss: 1.112165162563324\n",
      "epoch 36\n",
      "\t minibatch loss: 1.1108917236328124\n",
      "epoch 37\n",
      "\t minibatch loss: 1.1096924942731858\n",
      "epoch 38\n",
      "\t minibatch loss: 1.1085597062110901\n",
      "epoch 39\n",
      "\t minibatch loss: 1.107485894560814\n",
      "epoch 40\n",
      "\t minibatch loss: 1.1064649510383606\n",
      "epoch 41\n",
      "\t minibatch loss: 1.1054918974637986\n",
      "epoch 42\n",
      "\t minibatch loss: 1.1045627373456954\n",
      "epoch 43\n",
      "\t minibatch loss: 1.1036741703748703\n",
      "epoch 44\n",
      "\t minibatch loss: 1.102823092341423\n",
      "epoch 45\n",
      "\t minibatch loss: 1.1020067155361175\n",
      "epoch 46\n",
      "\t minibatch loss: 1.1012222695350646\n",
      "epoch 47\n",
      "\t minibatch loss: 1.1004667019844054\n",
      "epoch 48\n",
      "\t minibatch loss: 1.099737029671669\n",
      "epoch 49\n",
      "\t minibatch loss: 1.099030100107193\n",
      "epoch 50\n",
      "\t minibatch loss: 1.0983424639701844\n",
      "epoch 51\n",
      "\t minibatch loss: 1.0976712751388549\n",
      "epoch 52\n",
      "\t minibatch loss: 1.0970140331983567\n",
      "epoch 53\n",
      "\t minibatch loss: 1.0963693642616272\n",
      "epoch 54\n",
      "\t minibatch loss: 1.095736584663391\n",
      "epoch 55\n",
      "\t minibatch loss: 1.095115162730217\n",
      "epoch 56\n",
      "\t minibatch loss: 1.0945046657323838\n",
      "epoch 57\n",
      "\t minibatch loss: 1.0939044588804245\n",
      "epoch 58\n",
      "\t minibatch loss: 1.0933138519525527\n",
      "epoch 59\n",
      "\t minibatch loss: 1.0927320379018783\n",
      "epoch 60\n",
      "\t minibatch loss: 1.0921585500240325\n",
      "epoch 61\n",
      "\t minibatch loss: 1.091592715382576\n",
      "epoch 62\n",
      "\t minibatch loss: 1.0910341900587082\n",
      "epoch 63\n",
      "\t minibatch loss: 1.0904825133085252\n",
      "epoch 64\n",
      "\t minibatch loss: 1.0899374735355378\n",
      "epoch 65\n",
      "\t minibatch loss: 1.0893990403413774\n",
      "epoch 66\n",
      "\t minibatch loss: 1.0888669514656066\n",
      "epoch 67\n",
      "\t minibatch loss: 1.088341024518013\n",
      "epoch 68\n",
      "\t minibatch loss: 1.0878213983774185\n",
      "epoch 69\n",
      "\t minibatch loss: 1.0873077714443207\n",
      "epoch 70\n",
      "\t minibatch loss: 1.0868004089593888\n",
      "epoch 71\n",
      "\t minibatch loss: 1.0862990480661392\n",
      "epoch 72\n",
      "\t minibatch loss: 1.0858036279678345\n",
      "epoch 73\n",
      "\t minibatch loss: 1.0853142440319061\n",
      "epoch 74\n",
      "\t minibatch loss: 1.084830780029297\n",
      "epoch 75\n",
      "\t minibatch loss: 1.084353169798851\n",
      "epoch 76\n",
      "\t minibatch loss: 1.083881511092186\n",
      "epoch 77\n",
      "\t minibatch loss: 1.0834156543016433\n",
      "epoch 78\n",
      "\t minibatch loss: 1.082955681681633\n",
      "epoch 79\n",
      "\t minibatch loss: 1.0825015199184418\n",
      "epoch 80\n",
      "\t minibatch loss: 1.0820531994104385\n",
      "epoch 81\n",
      "\t minibatch loss: 1.081610827445984\n",
      "epoch 82\n",
      "\t minibatch loss: 1.081174224615097\n",
      "epoch 83\n",
      "\t minibatch loss: 1.0807435458898544\n",
      "epoch 84\n",
      "\t minibatch loss: 1.0803188073635102\n",
      "epoch 85\n",
      "\t minibatch loss: 1.0799001395702361\n",
      "epoch 86\n",
      "\t minibatch loss: 1.0794876545667649\n",
      "epoch 87\n",
      "\t minibatch loss: 1.0790812826156617\n",
      "epoch 88\n",
      "\t minibatch loss: 1.0786811572313308\n",
      "epoch 89\n",
      "\t minibatch loss: 1.0782871866226196\n",
      "epoch 90\n",
      "\t minibatch loss: 1.0778996592760086\n",
      "epoch 91\n",
      "\t minibatch loss: 1.0775183671712876\n",
      "epoch 92\n",
      "\t minibatch loss: 1.077143413424492\n",
      "epoch 93\n",
      "\t minibatch loss: 1.0767745661735535\n",
      "epoch 94\n",
      "\t minibatch loss: 1.0764117687940598\n",
      "epoch 95\n",
      "\t minibatch loss: 1.07605491399765\n",
      "epoch 96\n",
      "\t minibatch loss: 1.0757037591934204\n",
      "epoch 97\n",
      "\t minibatch loss: 1.0753581762313842\n",
      "epoch 98\n",
      "\t minibatch loss: 1.0750179010629655\n",
      "epoch 99\n",
      "\t minibatch loss: 1.0746828097105026\n",
      "epoch 100\n",
      "\t minibatch loss: 1.074352703690529\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "checkpoint = 10\n",
    "\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in range(num_batches):\n",
    "            fd = next_feed(batch)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            total_loss += l\n",
    "\n",
    "        total_loss /= num_batches    \n",
    "        loss_track.append(total_loss)\n",
    "        print('epoch {}'.format(epoch + 1))\n",
    "        print('\\t minibatch loss: {}'.format(total_loss))\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"model/seq2seq.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss 1.0744 after 10000 examples (batch_size=100)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f717c162518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_track)\n",
    "print('loss {:.4f} after {} examples (batch_size={})'.format(loss_track[-1], len(loss_track)*batch_size, batch_size))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
