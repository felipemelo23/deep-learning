{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/felipe/anaconda3/envs/deep-learning/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.4.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_token = '\\t'\n",
    "end_token = '\\n'\n",
    "batch_size = 100\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 10000\n",
    "data_path = 'data/fra.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_seqs = []\n",
    "target_seqs = []\n",
    "input_tokens = set()\n",
    "target_tokens = set()\n",
    "\n",
    "with open(data_path, 'r', encoding='utf-8') as file:\n",
    "    lines = file.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines)-1)]:\n",
    "    input_seq, target_seq = line.split('\\t')\n",
    "    \n",
    "    target_seq = start_token + target_seq + end_token\n",
    "    \n",
    "    input_seqs.append(input_seq)\n",
    "    target_seqs.append(target_seq)\n",
    "    \n",
    "    for token in input_seq:\n",
    "        if token not in input_tokens:\n",
    "            input_tokens.add(token)\n",
    "            \n",
    "    for token in target_seq:\n",
    "        if token not in target_tokens:\n",
    "            target_tokens.add(token)\n",
    "            \n",
    "input_tokens = sorted(list(input_tokens))\n",
    "target_tokens = sorted(list(target_tokens))\n",
    "\n",
    "num_encoder_tokens = len(input_tokens)\n",
    "num_decoder_tokens = len(target_tokens)\n",
    "\n",
    "max_encoder_seq_length = max([len(seq) for seq in input_seqs])\n",
    "max_decoder_seq_length = max([len(seq) for seq in target_seqs])\n",
    "\n",
    "input_token_index = dict([(token, index) for index, token in enumerate(input_tokens)])\n",
    "target_token_index = dict([(token, index) for index, token in enumerate(target_tokens)])\n",
    "\n",
    "rev_input_token_index = dict([(index, token) for index, token in enumerate(input_tokens)])\n",
    "rev_target_token_index = dict([(index, token) for index, token in enumerate(target_tokens)])\n",
    "\n",
    "encoder_input_data = np.zeros((len(input_seqs), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros((len(input_seqs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_seqs), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, (input_seq, target_seq) in enumerate(zip(input_seqs, target_seqs)):\n",
    "    for j, token in enumerate(input_seq):\n",
    "        encoder_input_data[i, j, input_token_index[token]] = 1.\n",
    "    for j, token in enumerate(target_seq):\n",
    "        decoder_input_data[i, j, target_token_index[token]] = 1.\n",
    "        if j > 0:\n",
    "            decoder_target_data[i, j-1, target_token_index[token]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = tf.placeholder(shape=(None,None,num_encoder_tokens), dtype=tf.float32, name='encoder_inputs')\n",
    "decoder_inputs = tf.placeholder(shape=(None,None,num_decoder_tokens), dtype=tf.float32, name='decoder_inputs')\n",
    "decoder_targets = tf.placeholder(shape=(None,None,num_decoder_tokens), dtype=tf.float32, name='decoder_targets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_cell = tf.contrib.rnn.LSTMCell(latent_dim)\n",
    "\n",
    "encoder_outputs, encoder_final_state = tf.nn.dynamic_rnn(\n",
    "    encoder_cell, encoder_inputs,\n",
    "    dtype=tf.float32,\n",
    ")\n",
    "\n",
    "del encoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_cell = tf.contrib.rnn.LSTMCell(latent_dim)\n",
    "\n",
    "decoder_outputs, decoder_final_state = tf.nn.dynamic_rnn(\n",
    "    decoder_cell, decoder_inputs,\n",
    "    dtype=tf.float32,\n",
    "    initial_state=encoder_final_state,\n",
    "    scope='plain_decoder'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_logits = tf.contrib.layers.linear(decoder_outputs, num_decoder_tokens)\n",
    "decoder_predicition = tf.argmax(decoder_logits, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stepwise_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=decoder_targets,\n",
    "    logits=decoder_logits,\n",
    ")\n",
    "\n",
    "loss = tf.reduce_mean(stepwise_cross_entropy)\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'decoder_targets:0' shape=(?, ?, 94) dtype=float32>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'fully_connected/BiasAdd:0' shape=(?, ?, 94) dtype=float32>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(input_data, batch_size=100):\n",
    "    num_batches = int(np.ceil(input_data.shape[0] / batch_size))\n",
    "    batches = []\n",
    "    for batch in np.arange(num_batches):\n",
    "        start = batch * batch_size\n",
    "        end = (batch+1) * batch_size\n",
    "        batches.append(input_data[start:end,:,:])\n",
    "        \n",
    "    return batches, num_batches   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_batches, _ = create_batches(encoder_input_data, batch_size)\n",
    "decoder_input_batches, _ = create_batches(decoder_input_data, batch_size)\n",
    "decoder_target_batches, num_batches = create_batches(decoder_target_data, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_feed(batch_index):\n",
    "    return {\n",
    "        encoder_inputs: encoder_input_batches[batch_index],\n",
    "        decoder_inputs: decoder_input_batches[batch_index],\n",
    "        decoder_targets: decoder_target_batches[batch_index]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "\t minibatch loss: 1.491408224105835\n",
      "epoch 2\n",
      "\t minibatch loss: 1.4785189986228944\n",
      "epoch 3\n",
      "\t minibatch loss: 1.4645978176593781\n",
      "epoch 4\n",
      "\t minibatch loss: 1.4475791996717453\n",
      "epoch 5\n",
      "\t minibatch loss: 1.422972947359085\n",
      "epoch 6\n",
      "\t minibatch loss: 1.3895596253871918\n",
      "epoch 7\n",
      "\t minibatch loss: 1.356590126156807\n",
      "epoch 8\n",
      "\t minibatch loss: 1.3295823299884797\n",
      "epoch 9\n",
      "\t minibatch loss: 1.309317536354065\n",
      "epoch 10\n",
      "\t minibatch loss: 1.2950420951843262\n",
      "epoch 11\n",
      "\t minibatch loss: 1.2840724736452103\n",
      "epoch 12\n",
      "\t minibatch loss: 1.2710555845499039\n",
      "epoch 13\n",
      "\t minibatch loss: 1.2518272715806962\n",
      "epoch 14\n",
      "\t minibatch loss: 1.2267791444063187\n",
      "epoch 15\n",
      "\t minibatch loss: 1.2062312895059586\n",
      "epoch 16\n",
      "\t minibatch loss: 1.1920768052339554\n",
      "epoch 17\n",
      "\t minibatch loss: 1.1806173831224442\n",
      "epoch 18\n",
      "\t minibatch loss: 1.170484355688095\n",
      "epoch 19\n",
      "\t minibatch loss: 1.1617117249965667\n",
      "epoch 20\n",
      "\t minibatch loss: 1.15437109708786\n",
      "epoch 21\n",
      "\t minibatch loss: 1.1482348477840423\n",
      "epoch 22\n",
      "\t minibatch loss: 1.14305905520916\n",
      "epoch 23\n",
      "\t minibatch loss: 1.138650695681572\n",
      "epoch 24\n",
      "\t minibatch loss: 1.1348644256591798\n",
      "epoch 25\n",
      "\t minibatch loss: 1.131583205461502\n",
      "epoch 26\n",
      "\t minibatch loss: 1.1287061601877213\n",
      "epoch 27\n",
      "\t minibatch loss: 1.1261515283584596\n",
      "epoch 28\n",
      "\t minibatch loss: 1.123856914639473\n",
      "epoch 29\n",
      "\t minibatch loss: 1.1217754423618316\n",
      "epoch 30\n",
      "\t minibatch loss: 1.119871097803116\n",
      "epoch 31\n",
      "\t minibatch loss: 1.1181149703264237\n",
      "epoch 32\n",
      "\t minibatch loss: 1.1164831668138504\n",
      "epoch 33\n",
      "\t minibatch loss: 1.1149558925628662\n",
      "epoch 34\n",
      "\t minibatch loss: 1.1135187536478042\n",
      "epoch 35\n",
      "\t minibatch loss: 1.112165162563324\n",
      "epoch 36\n",
      "\t minibatch loss: 1.1108917236328124\n",
      "epoch 37\n",
      "\t minibatch loss: 1.1096924942731858\n",
      "epoch 38\n",
      "\t minibatch loss: 1.1085597062110901\n",
      "epoch 39\n",
      "\t minibatch loss: 1.107485894560814\n",
      "epoch 40\n",
      "\t minibatch loss: 1.1064649510383606\n",
      "epoch 41\n",
      "\t minibatch loss: 1.1054918974637986\n",
      "epoch 42\n",
      "\t minibatch loss: 1.1045627373456954\n",
      "epoch 43\n",
      "\t minibatch loss: 1.1036741703748703\n",
      "epoch 44\n",
      "\t minibatch loss: 1.102823092341423\n",
      "epoch 45\n",
      "\t minibatch loss: 1.1020067155361175\n",
      "epoch 46\n",
      "\t minibatch loss: 1.1012222695350646\n",
      "epoch 47\n",
      "\t minibatch loss: 1.1004667019844054\n",
      "epoch 48\n",
      "\t minibatch loss: 1.099737029671669\n",
      "epoch 49\n",
      "\t minibatch loss: 1.099030100107193\n",
      "epoch 50\n",
      "\t minibatch loss: 1.0983424639701844\n",
      "epoch 51\n",
      "\t minibatch loss: 1.0976712751388549\n",
      "epoch 52\n",
      "\t minibatch loss: 1.0970140331983567\n",
      "epoch 53\n",
      "\t minibatch loss: 1.0963693642616272\n",
      "epoch 54\n",
      "\t minibatch loss: 1.095736584663391\n",
      "epoch 55\n",
      "\t minibatch loss: 1.095115162730217\n",
      "epoch 56\n",
      "\t minibatch loss: 1.0945046657323838\n",
      "epoch 57\n",
      "\t minibatch loss: 1.0939044588804245\n",
      "epoch 58\n",
      "\t minibatch loss: 1.0933138519525527\n",
      "epoch 59\n",
      "\t minibatch loss: 1.0927320379018783\n",
      "epoch 60\n",
      "\t minibatch loss: 1.0921585500240325\n",
      "epoch 61\n",
      "\t minibatch loss: 1.091592715382576\n",
      "epoch 62\n",
      "\t minibatch loss: 1.0910341900587082\n",
      "epoch 63\n",
      "\t minibatch loss: 1.0904825133085252\n",
      "epoch 64\n",
      "\t minibatch loss: 1.0899374735355378\n",
      "epoch 65\n",
      "\t minibatch loss: 1.0893990403413774\n",
      "epoch 66\n",
      "\t minibatch loss: 1.0888669514656066\n",
      "epoch 67\n",
      "\t minibatch loss: 1.088341024518013\n",
      "epoch 68\n",
      "\t minibatch loss: 1.0878213983774185\n",
      "epoch 69\n",
      "\t minibatch loss: 1.0873077714443207\n",
      "epoch 70\n",
      "\t minibatch loss: 1.0868004089593888\n",
      "epoch 71\n",
      "\t minibatch loss: 1.0862990480661392\n",
      "epoch 72\n",
      "\t minibatch loss: 1.0858036279678345\n",
      "epoch 73\n",
      "\t minibatch loss: 1.0853142440319061\n",
      "epoch 74\n",
      "\t minibatch loss: 1.084830780029297\n",
      "epoch 75\n",
      "\t minibatch loss: 1.084353169798851\n",
      "epoch 76\n",
      "\t minibatch loss: 1.083881511092186\n",
      "epoch 77\n",
      "\t minibatch loss: 1.0834156543016433\n",
      "epoch 78\n",
      "\t minibatch loss: 1.082955681681633\n",
      "epoch 79\n",
      "\t minibatch loss: 1.0825015199184418\n",
      "epoch 80\n",
      "\t minibatch loss: 1.0820531994104385\n",
      "epoch 81\n",
      "\t minibatch loss: 1.081610827445984\n",
      "epoch 82\n",
      "\t minibatch loss: 1.081174224615097\n",
      "epoch 83\n",
      "\t minibatch loss: 1.0807435458898544\n",
      "epoch 84\n",
      "\t minibatch loss: 1.0803188073635102\n",
      "epoch 85\n",
      "\t minibatch loss: 1.0799001395702361\n",
      "epoch 86\n",
      "\t minibatch loss: 1.0794876545667649\n",
      "epoch 87\n",
      "\t minibatch loss: 1.0790812826156617\n",
      "epoch 88\n",
      "\t minibatch loss: 1.0786811572313308\n",
      "epoch 89\n",
      "\t minibatch loss: 1.0782871866226196\n",
      "epoch 90\n",
      "\t minibatch loss: 1.0778996592760086\n",
      "epoch 91\n",
      "\t minibatch loss: 1.0775183671712876\n",
      "epoch 92\n",
      "\t minibatch loss: 1.077143413424492\n",
      "epoch 93\n",
      "\t minibatch loss: 1.0767745661735535\n",
      "epoch 94\n",
      "\t minibatch loss: 1.0764117687940598\n",
      "epoch 95\n",
      "\t minibatch loss: 1.07605491399765\n",
      "epoch 96\n",
      "\t minibatch loss: 1.0757037591934204\n",
      "epoch 97\n",
      "\t minibatch loss: 1.0753581762313842\n",
      "epoch 98\n",
      "\t minibatch loss: 1.0750179010629655\n",
      "epoch 99\n",
      "\t minibatch loss: 1.0746828097105026\n",
      "epoch 100\n",
      "\t minibatch loss: 1.074352703690529\n"
     ]
    }
   ],
   "source": [
    "loss_track = []\n",
    "checkpoint = 10\n",
    "\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in range(num_batches):\n",
    "            fd = next_feed(batch)\n",
    "            _, l = sess.run([train_op, loss], fd)\n",
    "            total_loss += l\n",
    "\n",
    "        total_loss /= num_batches    \n",
    "        loss_track.append(total_loss)\n",
    "        print('epoch {}'.format(epoch + 1))\n",
    "        print('\\t minibatch loss: {}'.format(total_loss))\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print('training interrupted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()\n",
    "save_path = saver.save(sess, \"model/seq2seq.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
